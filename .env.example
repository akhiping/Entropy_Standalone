# LLM Provider Configuration
OPENAI_API_KEY=your_openai_api_key_here
ANTHROPIC_API_KEY=your_anthropic_api_key_here
HUGGINGFACE_API_KEY=your_huggingface_api_key_here

# Vector Database
WEAVIATE_URL=http://localhost:8080
WEAVIATE_API_KEY=optional_weaviate_api_key

# Application Settings
ENVIRONMENT=development
LOG_LEVEL=INFO
DEBUG=true

# CORS Settings
FRONTEND_URL=http://localhost:5173
ALLOWED_ORIGINS=http://localhost:5173,http://localhost:3000

# Embedding Configuration
EMBEDDING_MODEL=text-embedding-3-small
EMBEDDING_PROVIDER=openai  # openai, huggingface
RERANKER_MODEL=BAAI/bge-reranker-base

# LLM Configuration
DEFAULT_LLM_PROVIDER=openai  # openai, anthropic, ollama
DEFAULT_MODEL=gpt-4-turbo-preview

# Branching Settings
SIMILARITY_THRESHOLD=0.7  # Threshold for topic deviation detection
MAX_CONTEXT_TOKENS=8000   # Maximum tokens for context window

# Rate Limiting
RATE_LIMIT_REQUESTS=100
RATE_LIMIT_WINDOW=60  # seconds

# Database (if using SQL for metadata)
DATABASE_URL=sqlite:///./entropy.db

# Cache Configuration
REDIS_URL=redis://localhost:6379
CACHE_TTL=3600  # seconds 
